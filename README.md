# Data-Engineering-Projects
### NYC Motor Vehicle Collisions
**Overview**:
The NYC Motor Vehicle Collisions dataset is a collection of traffic accident reports in New York City. It includes information such as the location, date and time, type of collision, and other factors that may have contributed to the accident. The data is provided by the New York City Police Department (NYPD) and is updated daily. It covers all five boroughs of the city and is available from 2012 to the present day. I, along with my team of 3 data engineers, are tasked to gather data, perform source system analysis and document findings, stage raw data, design dimensional model, design ETL pipelines and load data to integration schema, building interactive dashboards and reports using Tableau and Power BI.

***Click to view results:*** https://github.com/rohitpaul1998/Data-Engineering-Projects/tree/main/NYC_Motor_Vehicle_Collisions












### Retail Company Data Warehousing Solution
**Problem statement**: 
Build a data warehousing solution for a retail company that enables analysis of their product complaints and consumer data. The solution will include source system analysis (data profiling) in Alteryx, data staging, ETL development in Talend to extract, transform, and load data from data source into a Ralph Kimball-Star schema dimensional model in Google BigQuery, as well as development and testing of the entire data integration workflow. The resulting data will be visualized using interactive dashboards in Tableau

***Note:*** Project in progress.

***Click to view results:*** https://github.com/rohitpaul1998/Data-Engineering-Projects/tree/main/Retail_Data_Warehousing_Solution











### Data Pipeline for Social Media Analytics
1. Built a twitter scraping bot that scraped 5000 unstructured tweet data, cleansed the data using NumPy, Pandas, ensuring high data quality and accuracy
2. Loaded MongoDB with cleansed data for flexible data storage, executed analytical queries through Mongo Shell, discovering data patterns and popular tweets
3. Performed Sentiment Analysis on the stored data using TextBlob Machine Learning library, uncovering valuable insights into user sentiment
4. Loaded the processed data to Snowflake Data warehouse, transformed the data using SQL functions and extracted insightful information
5. Designed powerful data visualization dashboards in Power BI, presented trends and insights, leveraged DAX formulas and calculated sentiment remarks on the distribution of user sentiment scores, providing even deeper insights into user behaviour
6. Automated the data pipeline using Apache Airflow and monitored workflows resulting in efficient and reliable data processing


***Click to view results:*** https://github.com/rohitpaul1998/Data-Engineering-Projects/tree/main/Data_Pipeline_Social_Media

